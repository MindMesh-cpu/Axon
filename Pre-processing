import os
import numpy as np
import mne
from sklearn.model_selection import train_test_split

# ========== 配置 ==========
DATA_DIR = './data'  
SUBJECTS = ['S1IIIa', 'S2IIIa', 'S3IIIa']
BANDPASS = (1.0, 50.0)  # 带通滤波范围 (Hz)
NOTCH_FREQS = np.arange(50, 126, 50)  # 50Hz 工频陷波
TMIN, TMAX = 3.0, 7.0  # MI 想象窗口 (s)
TEST_SIZE = 0.2
RANDOM_STATE = 42

# MNE 使用的事件映射：字符串 → int（注意是 event_code，不是 label）
MNE_EVENT_ID = {
    '769': 1,  # 左手
    '770': 2,  # 右手
    '771': 3,  # 脚
    '772': 4   # 舌头
}

# 标签映射（用于训练 y）
LABEL_MAP = {
    '769': 0,
    '770': 1,
    '771': 2,
    '772': 3
}

# ========== 加载 & 预处理函数 ==========
def load_and_preprocess(subject):
    print(f"\n加载被试数据: {subject}")
    fpath = os.path.join(DATA_DIR, f'{subject}.gdf')
    raw = mne.io.read_raw_gdf(fpath, preload=True)

    # 只保留 EEG 通道
    eeg_picks = mne.pick_types(raw.info, eeg=True, eog=False)
    raw.pick(eeg_picks)

    # 滤波
    raw.filter(BANDPASS[0], BANDPASS[1], fir_design='firwin')
    raw.notch_filter(NOTCH_FREQS, fir_design='firwin')

    # 提取注释（annotations）
    annotations = raw.annotations
    print("Used Annotations descriptions:", set(annotations.description))

    # 构建事件数组和标签数组
    selected_events = []
    labels = []
    sfreq = raw.info['sfreq']

    for ann in annotations:
        desc = ann['description']
        if desc in MNE_EVENT_ID:
            sample = int(ann['onset'] * sfreq)
            selected_events.append([sample, 0, MNE_EVENT_ID[desc]])  # MNE 事件
            labels.append(LABEL_MAP[desc])  # 自定义标签 0~3

    selected_events = np.array(selected_events)
    labels = np.array(labels)

    print(f"筛选后事件数量: {len(selected_events)}")

    if len(selected_events) == 0:
        raise RuntimeError(f'未找到指定的运动想象事件！被试: {subject}')

    # 创建 Epochs
    epochs = mne.Epochs(
        raw, selected_events, event_id=MNE_EVENT_ID,
        tmin=TMIN, tmax=TMAX,
        baseline=None,
        preload=True,
        event_repeated='merge'
    )

    X = epochs.get_data()  # shape: (n_epochs, n_channels, n_times)
    y = labels

    print(f"数据形状: X={X.shape}, y={y.shape}")
    return X, y

# ========== 合并所有被试 ==========
X_all, y_all = [], []
for subj in SUBJECTS:
    X, y = load_and_preprocess(subj)
    X_all.append(X)
    y_all.append(y)

X_all = np.concatenate(X_all, axis=0)
y_all = np.concatenate(y_all, axis=0)
print(f'\n全部数据：X_all shape = {X_all.shape}, y_all shape = {y_all.shape}')

# ========== 划分训练/测试 ==========
X_train, X_test, y_train, y_test = train_test_split(
    X_all, y_all,
    test_size=TEST_SIZE,
    stratify=y_all,
    random_state=RANDOM_STATE
)
print(f'训练集：{X_train.shape}, 测试集：{X_test.shape}')

# ========== 保存为 .npz ==========
np.savez_compressed(
    os.path.join(DATA_DIR, 'IIIa_data.npz'),
    X_train=X_train, y_train=y_train,
    X_test=X_test, y_test=y_test
)

print('\n✅ Step 1 完成：数据已预处理并保存为 IIIa_data.npz')
